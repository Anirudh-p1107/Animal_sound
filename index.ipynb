{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO9Wlb4gsHf1SxNh9wJD9r6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anirudh-p1107/Animal_sound/blob/main/index.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# connect the dataset from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# installing required libraries\n",
        "!pip install librosa\n",
        "!pip install soundfile\n",
        "!pip install tensorflow\n",
        "\n",
        "# importing all the necessary libraries\n",
        "import numpy as np\n",
        "import os\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Path and Parameters\n",
        "DATASET_PATH = \"/content/drive/MyDrive/Train\"\n",
        "N_MELS, MAX_PAD_LEN, SAMPLE_RATE = 128, 174, 22050\n",
        "\n",
        "# Mel spectogram\n",
        "def extract_mel_spectrogram(file_path):\n",
        "    try:\n",
        "        y, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
        "        y, _ = librosa.effects.trim(y, top_db=20)\n",
        "        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=N_MELS, n_fft=2048, hop_length=256, fmax=8000)\n",
        "        mel_spec_db = librosa.power_to_db(mel_spec + 1e-9, ref=np.max)\n",
        "        mel_spec_norm = (mel_spec_db - np.min(mel_spec_db)) / (np.max(mel_spec_db) - np.min(mel_spec_db) + 1e-9)\n",
        "        mel_spec_padded = np.zeros((N_MELS, MAX_PAD_LEN))\n",
        "        mel_spec_padded[:, :min(MAX_PAD_LEN, mel_spec_norm.shape[1])] = mel_spec_norm[:, :MAX_PAD_LEN]\n",
        "        return mel_spec_padded\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# Data Processing\n",
        "X, y, labels = [], [], {}\n",
        "for idx, animal in enumerate(os.listdir(DATASET_PATH)):\n",
        "    animal_folder = os.path.join(DATASET_PATH, animal)\n",
        "    if os.path.isdir(animal_folder):\n",
        "        labels[idx] = animal\n",
        "        for file in filter(lambda f: f.endswith(\".wav\"), os.listdir(animal_folder)):\n",
        "            feature = extract_mel_spectrogram(os.path.join(animal_folder, file))\n",
        "            if feature is not None:\n",
        "                X.append(feature)\n",
        "                y.append(idx)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "if X:\n",
        "    X, y = np.array(X)[..., np.newaxis], to_categorical(y, num_classes=len(labels))\n",
        "else:\n",
        "    raise ValueError(\"No valid spectrograms found in dataset.\")\n",
        "\n",
        "# split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=np.argmax(y, axis=1))\n",
        "class_weight_dict = dict(enumerate(compute_class_weight('balanced', classes=np.unique(np.argmax(y, axis=1)), y=np.argmax(y, axis=1))))\n",
        "\n",
        "# CNN Model\n",
        "def create_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv2D(32, (3, 3), activation='relu', padding='same'), BatchNormalization(), MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'), BatchNormalization(), MaxPooling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'), BatchNormalization(), MaxPooling2D((2, 2)),\n",
        "        Conv2D(256, (3, 3), activation='relu', padding='same'), BatchNormalization(), MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'), BatchNormalization(), Dropout(0.5),\n",
        "        Dense(256, activation='relu'), Dropout(0.3), Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = create_model((N_MELS, MAX_PAD_LEN, 1), len(labels))\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test),\n",
        "          class_weight=class_weight_dict,\n",
        "          callbacks=[ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5, verbose=1),\n",
        "                     EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True, verbose=1),\n",
        "                     ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True, verbose=1)],\n",
        "          verbose=1)\n",
        "\n",
        "model.save(\"animal_audio.keras\")\n",
        "\n",
        "\n",
        "# Predictions\n",
        "def predict_animal(AUDIO_FILE):\n",
        "    \"\"\" Predicts the animal class from an audio file. \"\"\"\n",
        "    # Convert audio to Mel spectrogram\n",
        "    spectrogram = extract_mel_spectrogram(AUDIO_FILE)\n",
        "\n",
        "    # Reshape for CNN input (add batch and channel dimensions)\n",
        "    spectrogram = spectrogram[np.newaxis, ..., np.newaxis]  # Shape: (1, 128, 128, 1)\n",
        "\n",
        "    # Make prediction\n",
        "    predictions = model.predict(spectrogram)\n",
        "    predicted_label = np.argmax(predictions)\n",
        "\n",
        "    print(f\"Predicted Animal: {labels[predicted_label]} (Confidence: {predictions[0][predicted_label]:.2f})\")\n",
        "\n",
        "                                                            # output\n",
        "AUDIO_FILE = \"/content/drive/MyDrive/Test/Lion_9.wav\"       # lion\n",
        "predict_animal(AUDIO_FILE)\n",
        "\n",
        "AUDIO_FILE = \"/content/drive/MyDrive/Test/Monkey_51.wav\"       # monkey\n",
        "predict_animal(AUDIO_FILE)\n",
        "\n",
        "AUDIO_FILE = \"/content/drive/MyDrive/Test/Sheep_10.wav\"       # sheep\n",
        "predict_animal(AUDIO_FILE)\n",
        "\n",
        "AUDIO_FILE = \"/content/drive/MyDrive/Test/Cow_51.wav\"       # cow\n",
        "predict_animal(AUDIO_FILE)\n",
        "\n",
        "AUDIO_FILE = \"/content/drive/MyDrive/Test/Horse_51.wav\"       # horse\n",
        "predict_animal(AUDIO_FILE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqd0LFVuUoQR",
        "outputId": "7ce09b13-6bad-4d71-a93b-6e643ed8fedb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from soundfile) (2.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Epoch 1/50\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2242 - loss: 3.0049\n",
            "Epoch 1: val_accuracy improved from -inf to 0.10000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - accuracy: 0.2305 - loss: 2.9642 - val_accuracy: 0.1000 - val_loss: 2.3503 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6313 - loss: 1.1245\n",
            "Epoch 2: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6313 - loss: 1.1263 - val_accuracy: 0.1000 - val_loss: 2.5225 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7494 - loss: 0.8253\n",
            "Epoch 3: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7494 - loss: 0.8250 - val_accuracy: 0.1000 - val_loss: 2.7845 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7871 - loss: 0.6356\n",
            "Epoch 4: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7878 - loss: 0.6355 - val_accuracy: 0.1000 - val_loss: 3.0460 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8508 - loss: 0.4924\n",
            "Epoch 5: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8508 - loss: 0.4927 - val_accuracy: 0.1000 - val_loss: 3.2669 - learning_rate: 1.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9129 - loss: 0.3510\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.10000 to 0.12000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9123 - loss: 0.3516 - val_accuracy: 0.1200 - val_loss: 3.4767 - learning_rate: 1.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9228 - loss: 0.3064\n",
            "Epoch 7: val_accuracy improved from 0.12000 to 0.14000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 0.9226 - loss: 0.3061 - val_accuracy: 0.1400 - val_loss: 3.6582 - learning_rate: 5.0000e-05\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9341 - loss: 0.2181\n",
            "Epoch 8: val_accuracy did not improve from 0.14000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9344 - loss: 0.2181 - val_accuracy: 0.1200 - val_loss: 3.8281 - learning_rate: 5.0000e-05\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9400 - loss: 0.2256\n",
            "Epoch 9: val_accuracy did not improve from 0.14000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9404 - loss: 0.2253 - val_accuracy: 0.1100 - val_loss: 3.9203 - learning_rate: 5.0000e-05\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9706 - loss: 0.1554\n",
            "Epoch 10: val_accuracy did not improve from 0.14000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9707 - loss: 0.1553 - val_accuracy: 0.1000 - val_loss: 4.0320 - learning_rate: 5.0000e-05\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9794 - loss: 0.1404\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.14000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9790 - loss: 0.1405 - val_accuracy: 0.1000 - val_loss: 4.1643 - learning_rate: 5.0000e-05\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9765 - loss: 0.1384\n",
            "Epoch 12: val_accuracy did not improve from 0.14000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9765 - loss: 0.1383 - val_accuracy: 0.1000 - val_loss: 4.1320 - learning_rate: 2.5000e-05\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9897 - loss: 0.1187\n",
            "Epoch 13: val_accuracy did not improve from 0.14000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9893 - loss: 0.1187 - val_accuracy: 0.1000 - val_loss: 3.9854 - learning_rate: 2.5000e-05\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9925 - loss: 0.1014\n",
            "Epoch 14: val_accuracy did not improve from 0.14000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9924 - loss: 0.1017 - val_accuracy: 0.1300 - val_loss: 3.7442 - learning_rate: 2.5000e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9693 - loss: 0.1281\n",
            "Epoch 15: val_accuracy improved from 0.14000 to 0.18000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9696 - loss: 0.1275 - val_accuracy: 0.1800 - val_loss: 3.5137 - learning_rate: 2.5000e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9867 - loss: 0.0825\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\n",
            "Epoch 16: val_accuracy improved from 0.18000 to 0.21000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.9867 - loss: 0.0822 - val_accuracy: 0.2100 - val_loss: 3.3003 - learning_rate: 2.5000e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9930 - loss: 0.0901\n",
            "Epoch 17: val_accuracy improved from 0.21000 to 0.24000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.9930 - loss: 0.0898 - val_accuracy: 0.2400 - val_loss: 3.0612 - learning_rate: 1.2500e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9974 - loss: 0.0733\n",
            "Epoch 18: val_accuracy improved from 0.24000 to 0.32000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.9968 - loss: 0.0738 - val_accuracy: 0.3200 - val_loss: 2.8064 - learning_rate: 1.2500e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9909 - loss: 0.0804\n",
            "Epoch 19: val_accuracy improved from 0.32000 to 0.38000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.9907 - loss: 0.0806 - val_accuracy: 0.3800 - val_loss: 2.5571 - learning_rate: 1.2500e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9898 - loss: 0.0696\n",
            "Epoch 20: val_accuracy improved from 0.38000 to 0.40000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.9898 - loss: 0.0697 - val_accuracy: 0.4000 - val_loss: 2.2965 - learning_rate: 1.2500e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9886 - loss: 0.0872\n",
            "Epoch 21: val_accuracy improved from 0.40000 to 0.44000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9891 - loss: 0.0861 - val_accuracy: 0.4400 - val_loss: 2.0396 - learning_rate: 1.2500e-05\n",
            "Epoch 22/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9947 - loss: 0.0642\n",
            "Epoch 22: val_accuracy improved from 0.44000 to 0.49000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9946 - loss: 0.0642 - val_accuracy: 0.4900 - val_loss: 1.7953 - learning_rate: 1.2500e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9969 - loss: 0.0583\n",
            "Epoch 23: val_accuracy improved from 0.49000 to 0.53000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.9967 - loss: 0.0584 - val_accuracy: 0.5300 - val_loss: 1.5563 - learning_rate: 1.2500e-05\n",
            "Epoch 24/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9934 - loss: 0.0661\n",
            "Epoch 24: val_accuracy improved from 0.53000 to 0.64000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.9933 - loss: 0.0663 - val_accuracy: 0.6400 - val_loss: 1.3420 - learning_rate: 1.2500e-05\n",
            "Epoch 25/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9936 - loss: 0.0502\n",
            "Epoch 25: val_accuracy improved from 0.64000 to 0.66000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9937 - loss: 0.0504 - val_accuracy: 0.6600 - val_loss: 1.1457 - learning_rate: 1.2500e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9968 - loss: 0.0620\n",
            "Epoch 26: val_accuracy improved from 0.66000 to 0.74000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9967 - loss: 0.0620 - val_accuracy: 0.7400 - val_loss: 1.0171 - learning_rate: 1.2500e-05\n",
            "Epoch 27/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9966 - loss: 0.0599\n",
            "Epoch 27: val_accuracy improved from 0.74000 to 0.76000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9966 - loss: 0.0599 - val_accuracy: 0.7600 - val_loss: 0.9368 - learning_rate: 1.2500e-05\n",
            "Epoch 28/50\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9866 - loss: 0.0669\n",
            "Epoch 28: val_accuracy improved from 0.76000 to 0.79000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9867 - loss: 0.0670 - val_accuracy: 0.7900 - val_loss: 0.8772 - learning_rate: 1.2500e-05\n",
            "Epoch 29/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9930 - loss: 0.0681\n",
            "Epoch 29: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9931 - loss: 0.0677 - val_accuracy: 0.7900 - val_loss: 0.8489 - learning_rate: 1.2500e-05\n",
            "Epoch 30/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9948 - loss: 0.0571\n",
            "Epoch 30: val_accuracy improved from 0.79000 to 0.81000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9948 - loss: 0.0570 - val_accuracy: 0.8100 - val_loss: 0.8270 - learning_rate: 1.2500e-05\n",
            "Epoch 31/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9960 - loss: 0.0426\n",
            "Epoch 31: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9959 - loss: 0.0428 - val_accuracy: 0.8100 - val_loss: 0.8120 - learning_rate: 1.2500e-05\n",
            "Epoch 32/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9963 - loss: 0.0450\n",
            "Epoch 32: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9962 - loss: 0.0451 - val_accuracy: 0.8000 - val_loss: 0.8087 - learning_rate: 1.2500e-05\n",
            "Epoch 33/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9930 - loss: 0.0458\n",
            "Epoch 33: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9931 - loss: 0.0456 - val_accuracy: 0.8000 - val_loss: 0.8021 - learning_rate: 1.2500e-05\n",
            "Epoch 34/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9908 - loss: 0.0540\n",
            "Epoch 34: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9907 - loss: 0.0539 - val_accuracy: 0.8000 - val_loss: 0.7992 - learning_rate: 1.2500e-05\n",
            "Epoch 35/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9971 - loss: 0.0594\n",
            "Epoch 35: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9970 - loss: 0.0591 - val_accuracy: 0.7900 - val_loss: 0.7937 - learning_rate: 1.2500e-05\n",
            "Epoch 36/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9915 - loss: 0.0586\n",
            "Epoch 36: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9916 - loss: 0.0584 - val_accuracy: 0.7900 - val_loss: 0.8002 - learning_rate: 1.2500e-05\n",
            "Epoch 37/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9991 - loss: 0.0529\n",
            "Epoch 37: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9990 - loss: 0.0526 - val_accuracy: 0.7900 - val_loss: 0.7986 - learning_rate: 1.2500e-05\n",
            "Epoch 38/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9972 - loss: 0.0347\n",
            "Epoch 38: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9971 - loss: 0.0350 - val_accuracy: 0.7800 - val_loss: 0.8073 - learning_rate: 1.2500e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9998 - loss: 0.0299\n",
            "Epoch 39: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9997 - loss: 0.0301 - val_accuracy: 0.7800 - val_loss: 0.8090 - learning_rate: 1.2500e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9993 - loss: 0.0291\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9991 - loss: 0.0294 - val_accuracy: 0.7700 - val_loss: 0.8066 - learning_rate: 1.2500e-05\n",
            "Epoch 41/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9912 - loss: 0.0420\n",
            "Epoch 41: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9913 - loss: 0.0418 - val_accuracy: 0.7800 - val_loss: 0.8003 - learning_rate: 1.0000e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0388\n",
            "Epoch 42: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0388 - val_accuracy: 0.7900 - val_loss: 0.7991 - learning_rate: 1.0000e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9993 - loss: 0.0316\n",
            "Epoch 43: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9993 - loss: 0.0317 - val_accuracy: 0.7900 - val_loss: 0.7989 - learning_rate: 1.0000e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0285\n",
            "Epoch 44: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0285 - val_accuracy: 0.7900 - val_loss: 0.8021 - learning_rate: 1.0000e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0376\n",
            "Epoch 45: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0374 - val_accuracy: 0.7800 - val_loss: 0.8056 - learning_rate: 1.0000e-05\n",
            "Epoch 45: early stopping\n",
            "Restoring model weights from the end of the best epoch: 30.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522ms/step\n",
            "Predicted Animal: Lion (Confidence: 0.56)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Predicted Animal: Monkey (Confidence: 0.86)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "Predicted Animal: Sheep (Confidence: 1.00)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Predicted Animal: Cow (Confidence: 1.00)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
            "Predicted Animal: Horse (Confidence: 0.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vrXPceDIVOI0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
