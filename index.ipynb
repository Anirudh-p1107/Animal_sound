{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPBfQQIu3/AyBnudoghIUCt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anirudh-p1107/Wild_Echo/blob/main/index.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# connect the dataset from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# installing required libraries\n",
        "!pip install librosa\n",
        "!pip install soundfile\n",
        "!pip install tensorflow\n",
        "\n",
        "# importing all the necessary libraries\n",
        "import numpy as np\n",
        "import os\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Path and Parameters\n",
        "DATASET_PATH = \"/content/drive/MyDrive/Train\"\n",
        "N_MELS, MAX_PAD_LEN, SAMPLE_RATE = 128, 174, 22050\n",
        "\n",
        "# Mel spectogram\n",
        "def extract_mel_spectrogram(file_path):\n",
        "    try:\n",
        "        y, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
        "        y, _ = librosa.effects.trim(y, top_db=20)\n",
        "        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=N_MELS, n_fft=2048, hop_length=256, fmax=8000)\n",
        "        mel_spec_db = librosa.power_to_db(mel_spec + 1e-9, ref=np.max)\n",
        "        mel_spec_norm = (mel_spec_db - np.min(mel_spec_db)) / (np.max(mel_spec_db) - np.min(mel_spec_db) + 1e-9)\n",
        "        mel_spec_padded = np.zeros((N_MELS, MAX_PAD_LEN))\n",
        "        mel_spec_padded[:, :min(MAX_PAD_LEN, mel_spec_norm.shape[1])] = mel_spec_norm[:, :MAX_PAD_LEN]\n",
        "        return mel_spec_padded\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# Data Processing\n",
        "X, y, labels = [], [], {}\n",
        "for idx, animal in enumerate(os.listdir(DATASET_PATH)):\n",
        "    animal_folder = os.path.join(DATASET_PATH, animal)\n",
        "    if os.path.isdir(animal_folder):\n",
        "        labels[idx] = animal\n",
        "        for file in filter(lambda f: f.endswith(\".wav\"), os.listdir(animal_folder)):\n",
        "            feature = extract_mel_spectrogram(os.path.join(animal_folder, file))\n",
        "            if feature is not None:\n",
        "                X.append(feature)\n",
        "                y.append(idx)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "if X:\n",
        "    X, y = np.array(X)[..., np.newaxis], to_categorical(y, num_classes=len(labels))\n",
        "else:\n",
        "    raise ValueError(\"No valid spectrograms found in dataset.\")\n",
        "\n",
        "# split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=np.argmax(y, axis=1))\n",
        "class_weight_dict = dict(enumerate(compute_class_weight('balanced', classes=np.unique(np.argmax(y, axis=1)), y=np.argmax(y, axis=1))))\n",
        "\n",
        "# CNN Model\n",
        "def create_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv2D(32, (3, 3), activation='relu', padding='same'), BatchNormalization(), MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'), BatchNormalization(), MaxPooling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'), BatchNormalization(), MaxPooling2D((2, 2)),\n",
        "        Conv2D(256, (3, 3), activation='relu', padding='same'), BatchNormalization(), MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'), BatchNormalization(), Dropout(0.5),\n",
        "        Dense(256, activation='relu'), Dropout(0.3), Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = create_model((N_MELS, MAX_PAD_LEN, 1), len(labels))\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test),\n",
        "          class_weight=class_weight_dict,\n",
        "          callbacks=[ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5, verbose=1),\n",
        "                     EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True, verbose=1),\n",
        "                     ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True, verbose=1)],\n",
        "          verbose=1)\n",
        "\n",
        "model.save(\"animal_audio.keras\")\n",
        "\n",
        "\n",
        "# Predictions\n",
        "def predict_animal(AUDIO_FILE):\n",
        "    \"\"\" Predicts the animal class from an audio file. \"\"\"\n",
        "    # Convert audio to Mel spectrogram\n",
        "    spectrogram = extract_mel_spectrogram(AUDIO_FILE)\n",
        "\n",
        "    # Reshape for CNN input (add batch and channel dimensions)\n",
        "    spectrogram = spectrogram[np.newaxis, ..., np.newaxis]  # Shape: (1, 128, 128, 1)\n",
        "\n",
        "    # Make prediction\n",
        "    predictions = model.predict(spectrogram)\n",
        "    predicted_label = np.argmax(predictions)\n",
        "\n",
        "    print(f\"Predicted Animal: {labels[predicted_label]} (Confidence: {predictions[0][predicted_label]:.2f})\")\n",
        "\n",
        "                                                            # output\n",
        "AUDIO_FILE = \"/content/drive/MyDrive/Test/Lion_9.wav\"       # lion\n",
        "predict_animal(AUDIO_FILE)\n",
        "\n",
        "AUDIO_FILE = \"/content/drive/MyDrive/Test/Monkey_51.wav\"       # monkey\n",
        "predict_animal(AUDIO_FILE)\n",
        "\n",
        "AUDIO_FILE = \"/content/drive/MyDrive/Test/Sheep_10.wav\"       # sheep\n",
        "predict_animal(AUDIO_FILE)\n",
        "\n",
        "AUDIO_FILE = \"/content/drive/MyDrive/Test/Cow_51.wav\"       # cow\n",
        "predict_animal(AUDIO_FILE)\n",
        "\n",
        "AUDIO_FILE = \"/content/drive/MyDrive/Test/Horse_51.wav\"       # horse\n",
        "predict_animal(AUDIO_FILE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqd0LFVuUoQR",
        "outputId": "612519f6-3590-4116-e7a9-e0fab941ca46"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from soundfile) (2.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Epoch 1/50\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1918 - loss: 2.9447\n",
            "Epoch 1: val_accuracy improved from -inf to 0.10000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 147ms/step - accuracy: 0.2002 - loss: 2.9088 - val_accuracy: 0.1000 - val_loss: 2.3106 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5914 - loss: 1.2502\n",
            "Epoch 2: val_accuracy did not improve from 0.10000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5916 - loss: 1.2508 - val_accuracy: 0.1000 - val_loss: 2.3959 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7316 - loss: 0.8111\n",
            "Epoch 3: val_accuracy improved from 0.10000 to 0.11000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7320 - loss: 0.8088 - val_accuracy: 0.1100 - val_loss: 2.4832 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8008 - loss: 0.6045\n",
            "Epoch 4: val_accuracy improved from 0.11000 to 0.12000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.7994 - loss: 0.6051 - val_accuracy: 0.1200 - val_loss: 2.5301 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8560 - loss: 0.4751\n",
            "Epoch 5: val_accuracy did not improve from 0.12000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8554 - loss: 0.4785 - val_accuracy: 0.1000 - val_loss: 2.6592 - learning_rate: 1.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9204 - loss: 0.3036\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.12000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9194 - loss: 0.3037 - val_accuracy: 0.1000 - val_loss: 2.7623 - learning_rate: 1.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9547 - loss: 0.2309\n",
            "Epoch 7: val_accuracy did not improve from 0.12000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9547 - loss: 0.2303 - val_accuracy: 0.1000 - val_loss: 2.9672 - learning_rate: 5.0000e-05\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9414 - loss: 0.2426\n",
            "Epoch 8: val_accuracy did not improve from 0.12000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9415 - loss: 0.2426 - val_accuracy: 0.1000 - val_loss: 3.3202 - learning_rate: 5.0000e-05\n",
            "Epoch 9/50\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9676 - loss: 0.1653\n",
            "Epoch 9: val_accuracy did not improve from 0.12000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9676 - loss: 0.1644 - val_accuracy: 0.1000 - val_loss: 3.6917 - learning_rate: 5.0000e-05\n",
            "Epoch 10/50\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9813 - loss: 0.1450\n",
            "Epoch 10: val_accuracy did not improve from 0.12000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9808 - loss: 0.1446 - val_accuracy: 0.1000 - val_loss: 4.0234 - learning_rate: 5.0000e-05\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9764 - loss: 0.1203\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.12000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9762 - loss: 0.1205 - val_accuracy: 0.1000 - val_loss: 4.3477 - learning_rate: 5.0000e-05\n",
            "Epoch 12/50\n",
            "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9751 - loss: 0.1273\n",
            "Epoch 12: val_accuracy did not improve from 0.12000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9752 - loss: 0.1261 - val_accuracy: 0.1100 - val_loss: 4.3970 - learning_rate: 2.5000e-05\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9780 - loss: 0.1215\n",
            "Epoch 13: val_accuracy did not improve from 0.12000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9783 - loss: 0.1212 - val_accuracy: 0.1100 - val_loss: 4.2655 - learning_rate: 2.5000e-05\n",
            "Epoch 14/50\n",
            "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9822 - loss: 0.1091\n",
            "Epoch 14: val_accuracy did not improve from 0.12000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9828 - loss: 0.1076 - val_accuracy: 0.1200 - val_loss: 3.9215 - learning_rate: 2.5000e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9926 - loss: 0.0857\n",
            "Epoch 15: val_accuracy improved from 0.12000 to 0.15000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9926 - loss: 0.0854 - val_accuracy: 0.1500 - val_loss: 3.6565 - learning_rate: 2.5000e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9711 - loss: 0.1027\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\n",
            "Epoch 16: val_accuracy improved from 0.15000 to 0.20000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.9718 - loss: 0.1015 - val_accuracy: 0.2000 - val_loss: 3.2540 - learning_rate: 2.5000e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9953 - loss: 0.0735\n",
            "Epoch 17: val_accuracy improved from 0.20000 to 0.28000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9952 - loss: 0.0737 - val_accuracy: 0.2800 - val_loss: 2.8224 - learning_rate: 1.2500e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0602\n",
            "Epoch 18: val_accuracy improved from 0.28000 to 0.34000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0603 - val_accuracy: 0.3400 - val_loss: 2.4698 - learning_rate: 1.2500e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9941 - loss: 0.0707\n",
            "Epoch 19: val_accuracy improved from 0.34000 to 0.42000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9940 - loss: 0.0707 - val_accuracy: 0.4200 - val_loss: 2.1312 - learning_rate: 1.2500e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9963 - loss: 0.0522\n",
            "Epoch 20: val_accuracy improved from 0.42000 to 0.48000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9962 - loss: 0.0524 - val_accuracy: 0.4800 - val_loss: 1.8522 - learning_rate: 1.2500e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9911 - loss: 0.0560\n",
            "Epoch 21: val_accuracy improved from 0.48000 to 0.55000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9910 - loss: 0.0563 - val_accuracy: 0.5500 - val_loss: 1.6387 - learning_rate: 1.2500e-05\n",
            "Epoch 22/50\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9940 - loss: 0.0605\n",
            "Epoch 22: val_accuracy improved from 0.55000 to 0.59000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9940 - loss: 0.0605 - val_accuracy: 0.5900 - val_loss: 1.4808 - learning_rate: 1.2500e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9784 - loss: 0.0836\n",
            "Epoch 23: val_accuracy improved from 0.59000 to 0.70000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.9786 - loss: 0.0829 - val_accuracy: 0.7000 - val_loss: 1.3313 - learning_rate: 1.2500e-05\n",
            "Epoch 24/50\n",
            "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9876 - loss: 0.0518\n",
            "Epoch 24: val_accuracy improved from 0.70000 to 0.72000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.9883 - loss: 0.0524 - val_accuracy: 0.7200 - val_loss: 1.2116 - learning_rate: 1.2500e-05\n",
            "Epoch 25/50\n",
            "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9965 - loss: 0.0504\n",
            "Epoch 25: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9966 - loss: 0.0505 - val_accuracy: 0.7200 - val_loss: 1.1117 - learning_rate: 1.2500e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9991 - loss: 0.0555\n",
            "Epoch 26: val_accuracy improved from 0.72000 to 0.75000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9988 - loss: 0.0557 - val_accuracy: 0.7500 - val_loss: 1.0273 - learning_rate: 1.2500e-05\n",
            "Epoch 27/50\n",
            "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9972 - loss: 0.0488\n",
            "Epoch 27: val_accuracy improved from 0.75000 to 0.77000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.9973 - loss: 0.0484 - val_accuracy: 0.7700 - val_loss: 0.9641 - learning_rate: 1.2500e-05\n",
            "Epoch 28/50\n",
            "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9943 - loss: 0.0426\n",
            "Epoch 28: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9944 - loss: 0.0426 - val_accuracy: 0.7700 - val_loss: 0.9230 - learning_rate: 1.2500e-05\n",
            "Epoch 29/50\n",
            "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9986 - loss: 0.0473\n",
            "Epoch 29: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9980 - loss: 0.0481 - val_accuracy: 0.7700 - val_loss: 0.8937 - learning_rate: 1.2500e-05\n",
            "Epoch 30/50\n",
            "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9975 - loss: 0.0351\n",
            "Epoch 30: val_accuracy improved from 0.77000 to 0.79000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9975 - loss: 0.0356 - val_accuracy: 0.7900 - val_loss: 0.8563 - learning_rate: 1.2500e-05\n",
            "Epoch 31/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9991 - loss: 0.0408\n",
            "Epoch 31: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9990 - loss: 0.0409 - val_accuracy: 0.7900 - val_loss: 0.8427 - learning_rate: 1.2500e-05\n",
            "Epoch 32/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9983 - loss: 0.0372\n",
            "Epoch 32: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9981 - loss: 0.0376 - val_accuracy: 0.7900 - val_loss: 0.8449 - learning_rate: 1.2500e-05\n",
            "Epoch 33/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9989 - loss: 0.0378\n",
            "Epoch 33: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9987 - loss: 0.0381 - val_accuracy: 0.7800 - val_loss: 0.8320 - learning_rate: 1.2500e-05\n",
            "Epoch 34/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0362\n",
            "Epoch 34: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0364 - val_accuracy: 0.7800 - val_loss: 0.8261 - learning_rate: 1.2500e-05\n",
            "Epoch 35/50\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0383\n",
            "Epoch 35: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0383 - val_accuracy: 0.7900 - val_loss: 0.8252 - learning_rate: 1.2500e-05\n",
            "Epoch 36/50\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9930 - loss: 0.0468\n",
            "Epoch 36: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9929 - loss: 0.0468 - val_accuracy: 0.7800 - val_loss: 0.8238 - learning_rate: 1.2500e-05\n",
            "Epoch 37/50\n",
            "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9965 - loss: 0.0415\n",
            "Epoch 37: val_accuracy improved from 0.79000 to 0.80000, saving model to best_model.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9966 - loss: 0.0407 - val_accuracy: 0.8000 - val_loss: 0.8237 - learning_rate: 1.2500e-05\n",
            "Epoch 38/50\n",
            "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0261\n",
            "Epoch 38: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0265 - val_accuracy: 0.8000 - val_loss: 0.8287 - learning_rate: 1.2500e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9941 - loss: 0.0362\n",
            "Epoch 39: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9943 - loss: 0.0361 - val_accuracy: 0.8000 - val_loss: 0.8272 - learning_rate: 1.2500e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9955 - loss: 0.0371\n",
            "Epoch 40: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9955 - loss: 0.0370 - val_accuracy: 0.7800 - val_loss: 0.8281 - learning_rate: 1.2500e-05\n",
            "Epoch 41/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0284\n",
            "Epoch 41: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0284 - val_accuracy: 0.7800 - val_loss: 0.8268 - learning_rate: 1.2500e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9887 - loss: 0.0462\n",
            "Epoch 42: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9889 - loss: 0.0457 - val_accuracy: 0.8000 - val_loss: 0.8210 - learning_rate: 1.2500e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0425\n",
            "Epoch 43: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0415 - val_accuracy: 0.7900 - val_loss: 0.8245 - learning_rate: 1.2500e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9924 - loss: 0.0550\n",
            "Epoch 44: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9931 - loss: 0.0519 - val_accuracy: 0.8000 - val_loss: 0.8216 - learning_rate: 1.2500e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0249\n",
            "Epoch 45: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0252 - val_accuracy: 0.7900 - val_loss: 0.8205 - learning_rate: 1.2500e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0261\n",
            "Epoch 46: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0260 - val_accuracy: 0.7900 - val_loss: 0.8203 - learning_rate: 1.2500e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9954 - loss: 0.0338\n",
            "Epoch 47: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9957 - loss: 0.0328 - val_accuracy: 0.7900 - val_loss: 0.8146 - learning_rate: 1.2500e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0322\n",
            "Epoch 48: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0322 - val_accuracy: 0.7900 - val_loss: 0.8248 - learning_rate: 1.2500e-05\n",
            "Epoch 49/50\n",
            "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9995 - loss: 0.0207\n",
            "Epoch 49: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9993 - loss: 0.0211 - val_accuracy: 0.7900 - val_loss: 0.8312 - learning_rate: 1.2500e-05\n",
            "Epoch 50/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0208\n",
            "Epoch 50: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0209 - val_accuracy: 0.7800 - val_loss: 0.8359 - learning_rate: 1.2500e-05\n",
            "Restoring model weights from the end of the best epoch: 37.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "Predicted Animal: Lion (Confidence: 0.99)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Predicted Animal: Monkey (Confidence: 0.88)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Predicted Animal: Sheep (Confidence: 1.00)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "Predicted Animal: Cow (Confidence: 1.00)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Predicted Animal: Horse (Confidence: 1.00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QMQIgSX0iRdQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}